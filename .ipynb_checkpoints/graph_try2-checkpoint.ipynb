{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMB6+fXaojVwis960/x34ii",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harmeet-singh-bagga/ExplainableNLPsuite/blob/main/graph_try2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "VTsoTPy5f45W"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgX8TnMjTxYq",
        "outputId": "b453733b-8cd8-438e-fdbf-5e1ba03de945"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (10.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python pytesseract transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install tesseract-ocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6YiLLcxUBt7",
        "outputId": "537761c1-d0ca-4745-f893-d222ff76058e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjaxLarcbExG",
        "outputId": "4857be13-2366-4e22-a997-4863d54c63a7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMbCul_7bKVY",
        "outputId": "f4f76d30-cc62-4ef6-95d6-229e3ce69851"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid (permission: read).\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Required Libraries\n",
        "import cv2\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from transformers import pipeline\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "import torch\n",
        "\n",
        "# Step 1: Load the OCR Model for Graph Text Detection\n",
        "def extract_text_from_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # Preprocessing for better OCR results\n",
        "    gray = cv2.medianBlur(gray, 5)\n",
        "    text = pytesseract.image_to_string(gray)\n",
        "    return text\n",
        "\n",
        "# Step 2: Image Processing to Identify Graph Type\n",
        "def identify_graph_type(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    # Basic thresholding for edge detection\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
        "\n",
        "    # Hough Line Transform to detect lines in the image (useful for line/bar charts)\n",
        "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, 100, minLineLength=100, maxLineGap=10)\n",
        "\n",
        "    if lines is not None:\n",
        "        return \"Line Graph\"\n",
        "\n",
        "    # Future: Add more sophisticated classification methods (e.g., CNN) for other types\n",
        "    return \"Unknown Graph Type\"\n",
        "\n",
        "# Step 3: Hugging Face Pipeline for NLG Insights Generation\n",
        "def generate_insights(text_from_graph, prompt):\n",
        "    # Load pre-trained Hugging Face model for natural language generation\n",
        "    model_name = \"t5-base\"  # You can use larger models like T5-base, etc.\n",
        "    tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "    model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "    # Construct the input based on the prompt and the extracted text\n",
        "    input_text = f\"{prompt}: {text_from_graph}\"\n",
        "\n",
        "    # Tokenize the input\n",
        "    inputs = tokenizer.encode(\"summarize: \" + input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "    # Generate insights using the model\n",
        "    summary_ids = model.generate(inputs, max_length=1500, min_length=100, length_penalty=0.2, num_beams=6, early_stopping=True)\n",
        "\n",
        "    # Decode the generated response\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "# Step 4: Main Function to Run the Project\n",
        "def analyze_graph(image_path, prompt):\n",
        "    # Step 1: Extract Text from Graph\n",
        "    text_from_graph = extract_text_from_image(image_path)\n",
        "    print(\"Extracted text from graph:\", text_from_graph)\n",
        "\n",
        "    # Step 2: Identify Graph Type (For future classification expansion)\n",
        "    graph_type = identify_graph_type(image_path)\n",
        "    print(f\"Identified Graph Type: {graph_type}\")\n",
        "\n",
        "    # Step 3: Generate Insights using NLG\n",
        "    insights = generate_insights(text_from_graph, prompt)\n",
        "\n",
        "    return insights\n",
        "\n",
        "# Example Run\n",
        "if __name__ == \"__main__\":\n",
        "    image_path = \"test_p3.png\"  # Replace with the path to your graph image\n",
        "    prompt = \"There are some peculiar trends in the graph. Tell me some of them.\"\n",
        "\n",
        "    insights = analyze_graph(image_path, prompt)\n",
        "    print(\"Generated Insights: \", insights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bUAfMgAUoOh",
        "outputId": "57dcae5d-f7ee-4c75-cdfc-c9e9ae41caa7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted text from graph:  \n",
            "\n",
            "8 ie Tene Fox wpm ad?\n",
            "\n",
            " \n",
            "\f\n",
            "Identified Graph Type: Line Graph\n",
            "Generated Insights:  there are some peculiar trends in the graph, tell me some of them. ie: Tene Fox wpm ad? ie: 10 ie: 10 ie: 10 ie: 10 ie: 10 ie: 10 ie: 10 ie: 10 ie: 10 ie: 10 ie: 10 ie: 10 ie: 10 ie: 10 ie: 10 ie: 10 ie\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Graph Type Identification Function\n",
        "def identify_graph_type(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Edge detection for line/bar charts\n",
        "    edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
        "\n",
        "    # 1. Detect Line Graph using Hough Line Transform\n",
        "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, 100, minLineLength=100, maxLineGap=10)\n",
        "    if lines is not None:\n",
        "        return \"Line Graph\"\n",
        "\n",
        "    # 2. Detect Bar Chart using contours (rectangular shapes)\n",
        "    contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    for contour in contours:\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        # Heuristic: bars should be taller than they are wide\n",
        "        if h > w * 2:  # Adjust the ratio for specific detection criteria\n",
        "            return \"Bar Chart\"\n",
        "\n",
        "    # 3. Detect Pie Chart using Hough Circle Transform\n",
        "    circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, dp=1.2, minDist=50, param1=50, param2=30, minRadius=0, maxRadius=0)\n",
        "    if circles is not None:\n",
        "        return \"Pie Chart\"\n",
        "\n",
        "    # If no known type is detected\n",
        "    return \"Unknown Graph Type\"\n",
        "\n",
        "# Function to extract values from Line Graphs\n",
        "def extract_values_from_line_graph(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    edges = cv2.Canny(gray, 50, 150)\n",
        "\n",
        "    # Hough Line Transform for detecting line segments in the line graph\n",
        "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, 100, minLineLength=100, maxLineGap=10)\n",
        "\n",
        "    # Extract (x, y) coordinates of the detected line segments\n",
        "    data_points = []\n",
        "    for line in lines:\n",
        "        x1, y1, x2, y2 = line[0]\n",
        "        data_points.append((x1, y1))\n",
        "        data_points.append((x2, y2))\n",
        "\n",
        "    # Process these points to relate to the graph's axis (needs further axis parsing to map to real values)\n",
        "    return data_points\n",
        "\n",
        "# Function to extract values from Bar Charts\n",
        "def extract_values_from_bar_chart(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    edges = cv2.Canny(gray, 50, 150)\n",
        "\n",
        "    # Detect contours to identify bars\n",
        "    contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    bar_values = []\n",
        "    for contour in contours:\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        # Heuristic: Bars should be taller than wide\n",
        "        if h > w * 2:\n",
        "            bar_values.append(h)  # Height represents value, relative to the graphâ€™s scale\n",
        "\n",
        "    # To map these heights to real values, you'd need to parse axis labels\n",
        "    return bar_values\n",
        "\n",
        "# Function to extract values from Pie Charts\n",
        "def extract_values_from_pie_chart(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Hough Circle Transform to detect circular sections\n",
        "    circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, dp=1.2, minDist=50, param1=50, param2=30, minRadius=0, maxRadius=0)\n",
        "\n",
        "    if circles is not None:\n",
        "        circles = np.uint16(np.around(circles))\n",
        "        sections = len(circles[0, :])\n",
        "        return f\"{sections} sections in Pie Chart\"\n",
        "\n",
        "    return \"No sections found\"\n",
        "\n",
        "# Main function to detect the graph type and extract data\n",
        "def analyze_graph(image_path):\n",
        "    graph_type = identify_graph_type(image_path)\n",
        "    print(f\"Graph Type: {graph_type}\")\n",
        "\n",
        "    if graph_type == \"Line Graph\":\n",
        "        data_points = extract_values_from_line_graph(image_path)\n",
        "        print(f\"Data points extracted from Line Graph: {data_points}\")\n",
        "    elif graph_type == \"Bar Chart\":\n",
        "        bar_values = extract_values_from_bar_chart(image_path)\n",
        "        print(f\"Bar values extracted: {bar_values}\")\n",
        "    elif graph_type == \"Pie Chart\":\n",
        "        pie_info = extract_values_from_pie_chart(image_path)\n",
        "        print(f\"Pie chart info: {pie_info}\")\n",
        "    else:\n",
        "        print(\"Graph type is not recognized.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bwD4eb-iZRN",
        "outputId": "ca49f25f-a9ac-4d81-dccf-7e183bd9e816"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph Type: Line Graph\n",
            "Data points extracted from Line Graph: [(221, 29), (471, 29), (220, 21), (471, 21), (211, 182), (266, 296), (220, 27), (471, 27), (219, 23), (471, 23)]\n"
          ]
        }
      ]
    }
  ]
}