{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/harmeet-singh-bagga/ExplainableNLPsuite/blob/main/ReadingGraphData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UygXg-T5c8ny",
    "outputId": "f3040a2d-1423-402f-87ca-20e64a6416fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (10.4.0)\n",
      "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
      "Requirement already satisfied: tesseract in /usr/local/lib/python3.10/dist-packages (0.1.3)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
      "Collecting pyforest\n",
      "  Downloading pyforest-1.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: pyforest\n",
      "  Building wheel for pyforest (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyforest: filename=pyforest-1.1.2-py2.py3-none-any.whl size=15900 sha256=1544e6c125b1295caec09e476fe1134b3447ff2ba1a5b4e031a72b5f2a7dc497\n",
      "  Stored in directory: /root/.cache/pip/wheels/c5/ca/73/5cdc3d087111bfbdef90be5457aa03c00c0e32241b2752445c\n",
      "Successfully built pyforest\n",
      "Installing collected packages: pyforest\n",
      "Successfully installed pyforest-1.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python pillow pytesseract requests tesseract\n",
    "!pip install pyforest\n",
    "import pyforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0iEbG_2pg3Q1",
    "outputId": "f2e232bf-4d69-4954-9e5d-302085fa8c01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9 images from /content/sample_data.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def load_chart_images(folder_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".png\") or filename.endswith(\".jpg\"):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            images.append(image_path)\n",
    "    return images\n",
    "\n",
    "# Example usage\n",
    "folder_path = '/content/sample_data'  # Replace with your folder path\n",
    "chart_images = load_chart_images(folder_path)\n",
    "print(f\"Loaded {len(chart_images)} images from {folder_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xPdOEJ4rdCB5",
    "outputId": "af49abfd-3ae9-4524-eb88-c3c2a2f05d0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted bar data: [{'position': (0, 0), 'width': 629, 'height': 357}]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def extract_bars_data(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Find contours to detect bars\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    bar_data = []\n",
    "\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if w > 10 and h > 10:  # Filter out small noise\n",
    "            bar_data.append({\"position\": (x, y), \"width\": w, \"height\": h})\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imwrite('detected_bars.png', image)  # Save the image with detected bars\n",
    "    return bar_data\n",
    "\n",
    "# Example usage\n",
    "image_path = '/content/sample_data/0a0d8dc51eff3dca2f90451f048ceb81_d3d3LmludGVyZmF4LmpwCTIwMi4yMzAuMTM3LjM=-0-0.png'  # Replace with your bar chart image path\n",
    "bars = extract_bars_data(image_path)\n",
    "print(f\"Extracted bar data: {bars}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "V-Iggkhgdh9p",
    "outputId": "3b19a20c-4491-4602-b9fd-907ae07ded02"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted line data: [{'start': (23, 179), 'end': (306, 179)}, {'start': (18, 23), 'end': (305, 23)}, {'start': (19, 25), 'end': (306, 25)}, {'start': (22, 125), 'end': (306, 125)}, {'start': (25, 74), 'end': (306, 74)}, {'start': (23, 127), 'end': (306, 127)}, {'start': (28, 228), 'end': (305, 228)}, {'start': (24, 76), 'end': (306, 76)}, {'start': (28, 230), 'end': (306, 230)}, {'start': (24, 177), 'end': (306, 177)}, {'start': (44, 256), 'end': (44, 24)}, {'start': (306, 232), 'end': (306, 26)}, {'start': (304, 257), 'end': (304, 26)}, {'start': (42, 257), 'end': (42, 26)}, {'start': (54, 306), 'end': (261, 306)}, {'start': (84, 279), 'end': (270, 279)}, {'start': (54, 280), 'end': (269, 283)}, {'start': (53, 309), 'end': (261, 312)}, {'start': (28, 232), 'end': (305, 232)}]\n"
     ]
    }
   ],
   "source": [
    "def extract_lines_data(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "    # Detect lines using Hough Transform\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 100, minLineLength=100, maxLineGap=10)\n",
    "    line_data = []\n",
    "\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            line_data.append({\"start\": (x1, y1), \"end\": (x2, y2)})\n",
    "            cv2.line(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imwrite('detected_lines.png', image)  # Save the image with detected lines\n",
    "    return line_data\n",
    "\n",
    "# Example usage\n",
    "image_path = '/content/sample_data/011c2152453331ddfd58060d76ac655d_d3d3LnRpbGx2YXh0YW5hbHlzLnNlCTE5My4xMy43NS4xNjc=.xls-3-0.png'\n",
    "lines = extract_lines_data(image_path)\n",
    "print(f\"Extracted line data: {lines}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ILJAD_dj1ZV",
    "outputId": "f28d9794-8bb5-4d13-ad5b-bf57fbf66f6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted pie slice data: [{'center': (331, 26), 'radius': 14}]\n"
     ]
    }
   ],
   "source": [
    "def extract_pie_slices_data(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    _, thresh = cv2.threshold(blurred, 200, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours to detect circular slices\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    slice_data = []\n",
    "\n",
    "    for contour in contours:\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, 0.04 * perimeter, True)\n",
    "        if len(approx) > 8:  # Circular shapes\n",
    "            (x, y), radius = cv2.minEnclosingCircle(contour)\n",
    "            slice_data.append({\"center\": (int(x), int(y)), \"radius\": int(radius)})\n",
    "            cv2.circle(image, (int(x), int(y)), int(radius), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imwrite('detected_pie_slices.png', image)  # Save the image with detected slices\n",
    "    return slice_data\n",
    "\n",
    "# Example usage\n",
    "image_path = '/content/sample_data/0a0c983f2e69d6c45da004b071ffa8e7_d3d3LmFxdS5jYXQJODQuODguOTYuOTk=.xls-1-2.png'\n",
    "slices = extract_pie_slices_data(image_path)\n",
    "print(f\"Extracted pie slice data: {slices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Cf9ZazxkN_f",
    "outputId": "11188faa-5bef-4576-861a-78eac8c27588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted JSON: [\n",
      "  {\n",
      "    \"position\": [\n",
      "      50,\n",
      "      150\n",
      "    ],\n",
      "    \"width\": 100,\n",
      "    \"height\": 200\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def convert_data_to_json(chart_data):\n",
    "    return json.dumps(chart_data, indent=2)\n",
    "\n",
    "# Example usage\n",
    "chart_data = [{\"position\": (50, 150), \"width\": 100, \"height\": 200}]  # Example bar data\n",
    "json_data = convert_data_to_json(chart_data)\n",
    "print(f\"Converted JSON: {json_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u3LAtZuskRf3",
    "outputId": "6db16f2c-7b72-4d91-e527-b789a55321ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT Insights: Failed to get insights.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_gpt_insights(json_data, chart_type):\n",
    "    gpt_api_url = \"https://api.openai.com/v1/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer YOUR_API_KEY\",  # Replace with your OpenAI API key\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    prompt = f\"Analyze the following {chart_type} chart data: {json_data}. Provide key insights.\"\n",
    "    data = {\n",
    "        \"model\": \"gpt-3.5-turbo\",\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 100\n",
    "    }\n",
    "\n",
    "    response = requests.post(gpt_api_url, headers=headers, json=data)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['choices'][0]['text']\n",
    "    else:\n",
    "        return \"Failed to get insights.\"\n",
    "\n",
    "# Example usage\n",
    "chart_type = \"bar\"\n",
    "json_data = '{\"position\": [50, 150], \"width\": 100, \"height\": 200}'\n",
    "insights = get_gpt_insights(json_data, chart_type)\n",
    "print(f\"GPT Insights: {insights}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNAk6Z6OHzk//1UCI28OPAK",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
